{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalib Models\n",
    "In this notebook, we show how anomalib models could be initialized via Python API. As shown in [README.md](https://github.com/openvinotoolkit/anomalib#training), following models are supported in anomalib:\n",
    "\n",
    "- [CFlow](anomalib/models/cflow)\n",
    "- [DFM](anomalib/models/dfm)\n",
    "- [DFKDE](anomalib/models/dfkde)\n",
    "- [FastFlow](anomalib/models/fastflow)\n",
    "- [PatchCore](anomalib/models/patchcore)\n",
    "- [PADIM](anomalib/models/padim)\n",
    "- [STFPM](anomalib/models/stfpm)\n",
    "- [GANomaly](anomalib/models/ganomaly)\n",
    "\n",
    "\n",
    "## Data Module\n",
    "To train each model end-to-end, we do need to have a dataset. In this tutorial we will use MVTec AD DataModule. We assume that `datasets` directory is created in the `anomalib` root directory and `MVTec` dataset is located in `datasets` directory. Let's confirm this with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to the main anomalib root dir\n",
    "root = Path.cwd().parent.parent\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list((root / \"datasets\").iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we checked we have `datasets` directory and `MVTec` is already located in `datasets`, we could create the datamodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomalib.data.mvtec import MVTec\n",
    "\n",
    "MVTec??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = MVTec(\n",
    "    root=\"../../datasets/MVTec/\", \n",
    "    category=\"bottle\",\n",
    "    image_size=256,\n",
    "    train_batch_size=32,\n",
    "    test_batch_size=32,\n",
    "    num_workers=8,\n",
    "    task=\"segmentation\",\n",
    ")\n",
    "datamodule.setup()\n",
    "i, data = next(enumerate(datamodule.test_dataloader()))\n",
    "data[\"image\"].shape, data[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "Now that we have created MVTec datamodule, we could create the models. We could start with `PatchCore` since it is the ranked #1 model on the MVTec AD category on papers with code. \n",
    "\n",
    "Each model on anomalib has the following structure:\n",
    "```\n",
    "        anomalib/models/<model_name>\n",
    "        ├── README.md           # Readme file containing description and benchmarks.\n",
    "        ├── __init__.py         # Model initialization.\n",
    "        ├── config.yaml         # Stores the model configurations.  \n",
    "        ├── torch_model.py      # Torch model implementing the basic forward-pass mechanism.\n",
    "        ├── anomaly_map.py      # [Optional] module generating anomaly heatmaps.      \n",
    "        ├── lightning_model.py  # Lightning module implementing training mechanism\n",
    "        └── loss.py             # [Optional] module implementing loss computation. \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomalib.models.fastflow.torch_model import FastflowModel\n",
    "\n",
    "FastflowModel??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = FastflowModel(input_size=[256, 256], backbone=\"resnet18\", flow_steps=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, `torch_model` implements the basic forward-pass mechanism of the model for both `train` and `test` phases. In `train` phase, the model returns the training output such as feature maps. During the `test` phase, it returns the anomaly heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model.training = True\n",
    "train_output = torch_model(data[\"image\"])\n",
    "hidden_variables, log_jacobian = train_output\n",
    "hidden_variables[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model.training = False\n",
    "anomaly_map = torch_model(data[\"image\"])\n",
    "anomaly_map.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, when the `training` is `False`, meaning the model is in val/test/inference stage, it produces the `anomaly_map`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning Module\n",
    "The main module for each anomalib models is the `LightningModule` that stores the torch_model as its attributes and sorts out the train-test mechanism. Let's see how the LightningModule of `Fastflow` model is instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomalib.models.fastflow.lightning_model import Fastflow\n",
    "\n",
    "Fastflow??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Fastflow(\n",
    "    input_size=[256, 256], \n",
    "    backbone=\"resnet18\", \n",
    "    flow_steps=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training = True\n",
    "train_output = model(data[\"image\"])\n",
    "hidden_variables, log_jacobian = train_output\n",
    "hidden_variables[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the Lightning Module also returns the same output as `torch_model`. This is because it stores `torch_model` as its attribute and uses it in its `forward` method. Therefore, it is possible to call the forward-pass with `model(x)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.training = False\n",
    "anomaly_map = model(data[\"image\"])\n",
    "anomaly_map.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the `torch_model`, `lightning_module` also produces an `anomaly_map` when the `training` is set to `False`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('anomalib')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f26beec5b578f06009232863ae217b956681fd13da2e828fa5a0ecf8cf2ccd29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
